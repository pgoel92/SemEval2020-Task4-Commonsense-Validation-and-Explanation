{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HSuNtjz48w4K"
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "x_train = pd.read_csv('data/train/subtaskA_data_all.csv')\n",
    "y_train = pd.read_csv('data/train/subtaskA_answers_all.csv', header=None)\n",
    "x_dev = pd.read_csv('data/dev/subtaskA_dev_data.csv')\n",
    "y_dev = pd.read_csv('data/dev/subtaskA_gold_answers.csv', header=None)\n",
    "x_test = pd.read_csv('data/trial/taskA_trial_data.csv')\n",
    "y_test = pd.read_csv('data/trial/taskA_trial_answer.csv', header=None)\n",
    "x_submit = pd.read_csv('data/test/subtaskA_test_data.csv')\n",
    "y_train = y_train.rename(columns={0 : 'id',1: 'invalid_sent'})\n",
    "y_dev = y_dev.rename(columns={0 : 'id',1: 'invalid_sent'})\n",
    "y_test = y_test.rename(columns={0 : 'id',1: 'invalid_sent'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g9p5V2Xd8w4S"
   },
   "outputs": [],
   "source": [
    "xy = x_train.merge(y_train)\n",
    "items = []\n",
    "for row in xy.itertuples():\n",
    "    if row.invalid_sent == 0:\n",
    "        items.append({'id' : row.id, 'sent' : row.sent0, 'isvalid' : 0.0})\n",
    "        items.append({'id' : row.id, 'sent' : row.sent1, 'isvalid' : 1.0})\n",
    "    else:\n",
    "        items.append({'id' : row.id, 'sent' : row.sent0, 'isvalid' : 1.0})\n",
    "        items.append({'id' : row.id, 'sent' : row.sent1, 'isvalid' : 0.0})\n",
    "traindf = pd.DataFrame(items)\n",
    "\n",
    "xytest = x_test.merge(y_test)\n",
    "items = []\n",
    "for row in xytest.itertuples():\n",
    "    if row.invalid_sent == 0:\n",
    "        items.append({'id' : row.id, 'sent' : row.sent0, 'isvalid' : 0.0})\n",
    "        items.append({'id' : row.id, 'sent' : row.sent1, 'isvalid' : 1.0})\n",
    "    else:\n",
    "        items.append({'id' : row.id, 'sent' : row.sent0, 'isvalid' : 1.0})\n",
    "        items.append({'id' : row.id, 'sent' : row.sent1, 'isvalid' : 0.0})\n",
    "        \n",
    "testdf = pd.DataFrame(items)\n",
    "\n",
    "xydev = x_dev.merge(y_dev)\n",
    "items = []\n",
    "for row in xydev.itertuples():\n",
    "    if row.invalid_sent == 0:\n",
    "        items.append({'id' : row.id, 'sent' : row.sent0, 'isvalid' : 0.0})\n",
    "        items.append({'id' : row.id, 'sent' : row.sent1, 'isvalid' : 1.0})\n",
    "    else:\n",
    "        items.append({'id' : row.id, 'sent' : row.sent0, 'isvalid' : 1.0})\n",
    "        items.append({'id' : row.id, 'sent' : row.sent1, 'isvalid' : 0.0})\n",
    "devdf = pd.DataFrame(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u8xbxuTo8w4W"
   },
   "source": [
    "## Baseline - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UFlCOu1O8w4X",
    "outputId": "4e416d86-6805-425b-df4e-ad145261d93e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/goelprat/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/goelprat/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "ps = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english')) \n",
    "def preprocess(x):\n",
    "    x = x.lower()\n",
    "    tokens = word_tokenize(x)\n",
    "    filtered_tokens = [w for w in tokens if not w in stop_words] \n",
    "    return ' '.join([ps.stem(t) for t in filtered_tokens])\n",
    "trainpdf = traindf.sent.apply(preprocess)\n",
    "testpdf = testdf.sent.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hXh3z2sE8w4f",
    "outputId": "0a642d7c-5e40-409a-d474-7aacb50b2f08"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(min_df=0, lowercase=False, max_features=3000)\n",
    "vectorizer.fit(trainpdf)\n",
    "len(vectorizer.vocabulary_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4GAxRpUW8w4i"
   },
   "outputs": [],
   "source": [
    "X_train = vectorizer.transform(trainpdf)\n",
    "X_test = vectorizer.transform(testpdf)\n",
    "Y_train = traindf.isvalid\n",
    "Y_test = testdf.isvalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rOGDfHDF8w4l",
    "outputId": "bfd2120d-1357-4422-9c20-9d026085a1e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kj5Z39Ed8w4o",
    "outputId": "ba6c60fa-8131-4ec7-cefb-710aafdee4c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5774369124195943"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = classifier.score(X_test, Y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AX3KoZl98w4r"
   },
   "source": [
    "Baseline accuracy is 57%. I now use Keras to essentially do simple logistic regression just to practice grid search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EgYIYQUb8w4s",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Answer 5\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "### Answer 3\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def create_model(optimizer='sgd'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 1, activation = 'sigmoid', input_dim = 3000))\n",
    "    # Describe the loss and how it is optimized\n",
    "    model.compile(loss = 'mean_squared_error', optimizer = optimizer, metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "def grid_search():\n",
    "    optimizers = []\n",
    "    model = KerasClassifier(build_fn=create_model)\n",
    "    optimizer = ['SGD', 'Adam', 'RMSProp']\n",
    "    param_grid = dict(epochs=[20, 40, 60], batch_size=[20, 40, 60], optimizer=optimizer)\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=5)\n",
    "    grid_result = grid.fit(x_train, y_train)\n",
    "\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "        \n",
    "model = create_model(optimizer='adam')\n",
    "model.fit(X_train, Y_train, epochs=40, batch_size=40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I3vml1gQ8w4w",
    "outputId": "acfe45c4-bebc-4b3e-9dde-0e6f8fa8516f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4042/4042 [==============================] - 0s 57us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.24135216026539735, 0.5821375846862793]"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S5jaUWFq8w40"
   },
   "source": [
    "## Using BERT with pretrained weights to get sentence embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qbipxZcX8w42"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b8Cey0dP8w45"
   },
   "outputs": [],
   "source": [
    "def bert_input(df):\n",
    "    bertdf = df.sent.apply(lambda x : \"[CLS] \" + x + \" [SEP]\")\n",
    "    bertdf_tokenized = bertdf.apply((lambda x: tokenizer.encode(x)))\n",
    "    max_len = 0\n",
    "    for i in bertdf_tokenized.values:\n",
    "        if len(i) > max_len:\n",
    "            max_len = len(i)\n",
    "\n",
    "    padded = np.array([i + [0]*(max_len-len(i)) for i in bertdf_tokenized.values])\n",
    "    attention_mask = np.where(padded != 0, 1, 0)\n",
    "    input_ids = torch.tensor(padded)  \n",
    "    attention_mask = torch.tensor(attention_mask)\n",
    "\n",
    "    return input_ids, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gjo-Lg028w4_"
   },
   "outputs": [],
   "source": [
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "input_ids_train, attention_mask_train = bert_input(traindf)\n",
    "with torch.no_grad():\n",
    "    hidden_train = model(input_ids_train, attention_mask=attention_mask_train)\n",
    "features_train = hidden_train[0][:,0,:].numpy()\n",
    "\n",
    "input_ids_test, attention_mask_test = bert_input(testdf)\n",
    "with torch.no_grad():\n",
    "    hidden_test = model(input_ids_test, attention_mask=attention_mask_test)\n",
    "features_test = hidden_test[0][:,0,:].numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XCSo-4zz8w5E"
   },
   "outputs": [],
   "source": [
    "Y_train = traindf.isvalid\n",
    "Y_test = testdf.isvalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4v8iia-e8w5G",
    "outputId": "fed59d35-8fc1-4e61-ae10-4cd9bccf7eab"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/goelprat/miniconda3/envs/fastai/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(features_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vmXB4JbK8w5M",
    "outputId": "1e93080d-5460-4d5d-b015-d913ae0fa492"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6264225630875804"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = classifier.score(features_test, Y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "picm96sP8w5Q"
   },
   "source": [
    "## Using BERT to get perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9nAah3fW8w5R"
   },
   "source": [
    "In the [paper](https://arxiv.org/abs/1906.00363) published along with this task, the authors claim to get 70% accuracy by using BERT to get sentence perplexity. I try to replicate that claim in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vYDjI9DY8w5R"
   },
   "outputs": [],
   "source": [
    "bertdf = traindf.sent.apply(lambda x : \"[CLS] \" + x + \" [SEP]\")\n",
    "testbertdf = testdf.sent.apply(lambda x : \"[CLS] \" + x + \" [SEP]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertForMaskedLM, BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "def get_bert_inputs(df):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    token_type_ids = []\n",
    "    for i, row in df.iterrows():\n",
    "        tokendict = tokenizer.encode_plus(row['sent'], max_length=25, pad_to_max_length=True)\n",
    "        input_ids.append(tokendict['input_ids'])\n",
    "        attention_masks.append(tokendict['attention_mask'])\n",
    "        token_type_ids.append(tokendict['token_type_ids'])\n",
    "    return torch.tensor(input_ids), torch.tensor(attention_masks), torch.tensor(token_type_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids, attention_masks, token_type_ids = get_bert_inputs(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UmBnfRQS8w5U",
    "outputId": "82bc22a9-b11f-4a73-a130-6e3692c87b68"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /Users/goelprat/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening under the hood, activate the logger as follows\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "train_tensors = []\n",
    "for sent in bertdf:\n",
    "    # Tokenize input\n",
    "    tokenized_text = tokenizer.tokenize(sent)\n",
    "    # Convert token to vocabulary indices\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    train_tensors.append(tokens_tensor)\n",
    "    \n",
    "test_tensors = []\n",
    "for sent in testbertdf:\n",
    "    # Tokenize input\n",
    "    tokenized_text = tokenizer.tokenize(sent)\n",
    "    # Convert token to vocabulary indices\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    test_tensors.append(tokens_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DyZEwimz8w5W",
    "outputId": "3ad62b3a-d9e6-4a72-cbb4-17f557a135c7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import BertForMaskedLM\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AHJvIRh08w5Z",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "loss_fct = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def run_tokens(s):\n",
    "    tokenized_text = tokenizer.tokenize(s)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_ids = [0] * tokens_tensor.shape[1]\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "    prediction = model(tokens_tensor, token_type_ids=segments_tensors)\n",
    "    predictions = prediction[0]\n",
    "    predicted_tokens = []\n",
    "    for i in range(tokens_tensor.shape[1]):\n",
    "        predicted_index = torch.argmax(predictions[0, i]).item()\n",
    "        predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n",
    "        predicted_tokens.append(predicted_token)\n",
    "    return predicted_tokens\n",
    "\n",
    "def run_perp(s):\n",
    "    tokenized_text = tokenizer.tokenize(s)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_ids = [0] * tokens_tensor.shape[1]\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "    predictions = model(tokens_tensor, token_type_ids=segments_tensors)\n",
    "    loss = loss_fct(predictions[0].squeeze(),tokens_tensor.squeeze()).data \n",
    "    return math.exp(loss)\n",
    "\n",
    "def run(sents, mode):\n",
    "    model.eval()\n",
    "    f = run_perp if mode == 'perp' else run_tokens\n",
    "    out = []\n",
    "    with torch.no_grad():\n",
    "        for sent in sents:\n",
    "            out.append(f(sent))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
    "class text_dataset(Dataset):\n",
    "    def __init__(self,x_y_list):\n",
    "        self.x_y_list = x_y_list\n",
    "        \n",
    "    def __getitem__(self,index):           \n",
    "        input_ids = self.x_y_list[0][index]\n",
    "        token_type_ids = self.x_y_list[1][index]\n",
    "        attention_mask = self.x_y_list[2][index]\n",
    "        label = self.x_y_list[3][index]\n",
    "        return input_ids, token_type_ids, attention_mask, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x_y_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "batch_size = 1\n",
    "epochs = 10\n",
    "isvalid = torch.tensor(testdf.isvalid)\n",
    "test_lists = [input_ids, attention_masks, token_type_ids, isvalid]\n",
    "test_dataset = text_dataset(x_y_list = test_lists)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "perps = []\n",
    "loss_fct = torch.nn.CrossEntropyLoss()\n",
    "for inputs, masks, token_types, target in test_loader:\n",
    "    inputs = inputs.to(device)\n",
    "    #masks = masks.to(device)\n",
    "    #token_types = token_types.to(device)\n",
    "    #import pdb; pdb.set_trace()\n",
    "    output = model(inputs, masked_lm_labels=inputs)\n",
    "    #loss = loss_fct(output[0].squeeze(),inputs.squeeze()).data \n",
    "    perps.append(math.exp(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he was sent to a restaurant for treatment after a car crash 53.811206193880054\n",
      "he was sent to a hospital for treatment after a car crash 56.52741072294196\n"
     ]
    }
   ],
   "source": [
    "i = 10\n",
    "sent0 = testdf.sent[i]\n",
    "sent1 = testdf.sent[i + 1]\n",
    "input_ids0 = torch.tensor(tokenizer.encode(sent0, add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "input_ids1 = torch.tensor(tokenizer.encode(sent1, add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n",
    "outputs0 = model(input_ids0, masked_lm_labels=input_ids0)\n",
    "outputs1 = model(input_ids1, masked_lm_labels=input_ids1)\n",
    "\n",
    "print(sent0, math.exp(outputs0[0]))\n",
    "print(sent1, math.exp(outputs1[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'money can be used for buying cars'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf.sent[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "alOF0Lz78w5d",
    "outputId": "747d9449-09a3-4569-c98b-29be741cad86"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[42.116081023755655, 38.70850197316724]"
      ]
     },
     "execution_count": 133,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = ['[CLS] my sister eats an apple after breakfast every day . [SEP]', '[CLS] my sister eats a stone after breakfast every day . [SEP]']\n",
    "run(sents, 'perp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-52BX8IJ8w5g"
   },
   "outputs": [],
   "source": [
    "sents = []\n",
    "for s in testdf.sent:\n",
    "    sents.append('[CLS] ' + s + ' . [SEP]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7q8TibEd8w5j",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "perps = run(sents, 'perp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "49SW3n-d8w5l",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_results_from_perps(perps):\n",
    "    results = []\n",
    "    for i in range(0, len(perps), 2):\n",
    "        if perps[i] < perps[i + 1]:\n",
    "            results.append(1)\n",
    "        else:\n",
    "            results.append(0)\n",
    "    return results\n",
    "\n",
    "results = get_results_from_perps(perps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 49.4805%\r\n"
     ]
    }
   ],
   "source": [
    "pd.concat([x_test.id, pd.Series(results)], axis=1).to_csv('./predictions.csv', header=False, index=False)\n",
    "!python3 eval/taskA_scorer.py --gold-labels data/trial/taskA_trial_answer.csv --pred-labels predictions.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nfpPSBrU8w5o"
   },
   "source": [
    "I was unable to get better than random results using BERT to get sentence probability. I believe this is because BERT outputs probability conditional on all the other tokens. This means that multiplying the probabilities for tokens in a sentence does not yield the probability of the sentence. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MOVYL3gG8w5p"
   },
   "source": [
    "## Using GPT-2 to get sentence probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xeTX5Kyq8w5q",
    "outputId": "1aca1e55-5625-4df6-c27c-cc26e8784287",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, GPT2Model\n",
    "gpt_model = GPT2Model.from_pretrained('gpt2')\n",
    "gpt_model.eval()\n",
    "# Load pre-trained model (weights)\n",
    "gpt_model_lm = GPT2LMHeadModel.from_pretrained('gpt2-large')\n",
    "gpt_model_lm.eval()\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "loss_fct = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AeXgm52Y8w5t"
   },
   "outputs": [],
   "source": [
    "def gpt_input(df):\n",
    "    gptdf = df.sent.apply(lambda x : ' <|endoftext|> ' + x)\n",
    "    gptdf_tokenized = gptdf.apply((lambda x: tokenizer.encode(x)))\n",
    "    max_len = 0\n",
    "    for i in gptdf_tokenized.values:\n",
    "        if len(i) > max_len:\n",
    "            max_len = len(i)\n",
    "\n",
    "    padded = np.array([i + [0]*(max_len-len(i)) for i in gptdf_tokenized.values])\n",
    "    attention_mask = np.where(padded != 0, 1, 0)\n",
    "    input_ids = torch.tensor(padded)  \n",
    "    attention_mask = torch.tensor(attention_mask)\n",
    "\n",
    "    return input_ids, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A2j5SYXW8w5x"
   },
   "outputs": [],
   "source": [
    "def gpt_predictions(sentence, model):\n",
    "    sentence = ' <|endoftext|> ' + sentence\n",
    "    tokenize_input = tokenizer.tokenize(sentence, add_prefix_space=True)\n",
    "    tokens_tensor = torch.tensor([tokenizer.convert_tokens_to_ids(tokenize_input)])\n",
    "    return model(tokens_tensor)\n",
    "    \n",
    "def get_last_hidden_state(sentence, model):\n",
    "    predictions = gpt_predictions(sentence, model)\n",
    "    return predictions[0].squeeze()[-1]\n",
    "\n",
    "def gpt_score(sentence):\n",
    "    sentence = ' <|endoftext|> ' + sentence\n",
    "    tokenize_input = tokenizer.tokenize(sentence, add_prefix_space=True)\n",
    "    tokens_tensor = torch.tensor([tokenizer.convert_tokens_to_ids(tokenize_input)])\n",
    "    predictions=gpt_model_lm(tokens_tensor)\n",
    "    loss = loss_fct(predictions[0].squeeze()[:-1],tokens_tensor.squeeze()[1:]).data \n",
    "    return math.exp(loss)\n",
    "\n",
    "def gpt_tokens(input_sentence):\n",
    "    sentence = '<|endoftext|> ' + input_sentence\n",
    "    tokenize_input = tokenizer.tokenize(sentence)\n",
    "    tokens_tensor = torch.tensor([tokenizer.convert_tokens_to_ids(tokenize_input)])\n",
    "    predictions =gpt_model(tokens_tensor)\n",
    "    predicted_tokens = []\n",
    "    for i in range(tokens_tensor.shape[1]):\n",
    "        predicted_index = torch.argmax(predictions[0][0, i]).item()\n",
    "        predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n",
    "        predicted_tokens.append(predicted_token)\n",
    "    return predicted_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EPij7uPM8w50"
   },
   "outputs": [],
   "source": [
    "def run(sents, mode='perp'):\n",
    "    out = []\n",
    "    with torch.no_grad():\n",
    "        for sent in sents:\n",
    "            if mode == 'perp':\n",
    "                out.append(gpt_score(sent))\n",
    "            else:\n",
    "                out.append(gpt_tokens(sent))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x5BwLnkY8w54",
    "outputId": "b4c3e957-7eee-4967-f15b-5d33f31e5337"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[628.2036629979144, 448.928654083428]"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(['he put an elephant into the fridge', 'he put a turkey into the fridge'], mode='perp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lbP0WK508w58"
   },
   "outputs": [],
   "source": [
    "input_ids, attention_mask = gpt_input(testdf)\n",
    "with torch.no_grad():\n",
    "    predictions = gpt_model_lm(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FM9AzBU78w5_",
    "outputId": "f3643fc9-dbe9-4196-b3cb-41b1e42cd371"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150.6329864510042"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 1\n",
    "loss = loss_fct(predictions[0][i, :-1, :],input_ids[i, 1:]).data \n",
    "math.exp(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "idaiWkbm8w6E"
   },
   "outputs": [],
   "source": [
    "perps = []\n",
    "for i in range(4042):\n",
    "    loss = loss_fct(predictions[0][i, :-1, :],input_ids[i, 1:]).data \n",
    "    perps.append(math.exp(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y_xKBiKR8w6G"
   },
   "outputs": [],
   "source": [
    "def get_results_from_perps(perps):\n",
    "    results = []\n",
    "    for i in range(0, len(perps), 2):\n",
    "        if perps[i] < perps[i + 1]:\n",
    "            results.append(1)\n",
    "        else:\n",
    "            results.append(0)\n",
    "    return results\n",
    "\n",
    "results = get_results_from_perps(perps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o2gPSP5S8w6T",
    "outputId": "e7066fd3-ba16-4645-a56e-d47696a665b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 71.3508%\n"
     ]
    }
   ],
   "source": [
    "pd.concat([x_test.id, pd.Series(results)], axis=1).to_csv('./predictions.csv', header=False, index=False)\n",
    "!python3 eval/taskA_scorer.py --gold-labels data/trial/taskA_trial_answer.csv --pred-labels predictions.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XCNOkF6r8w6V"
   },
   "source": [
    "These results using the GPT-2 small model match the ~70% baseline reported in the paper. \n",
    "Using the large model, I was able to get 71.35% accuracy. \n",
    "\n",
    "Next, I experiment with using the final hidden state output of the GPT-2 model to classify a sentence as for or against common sense. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kkYNUGwF8w6V"
   },
   "outputs": [],
   "source": [
    "def run_classification(sents, model):\n",
    "    import numpy as np\n",
    "    x = np.zeros((len(sents), 768))\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(sents)):\n",
    "            h = get_last_hidden_state(sents[i], model)\n",
    "            x[i] = h\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8FHAETc58w6X"
   },
   "outputs": [],
   "source": [
    "sents = [x for x in traindf.sent]\n",
    "x = run_classification(sents, gpt_model)\n",
    "y = traindf.isvalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sECj0Sya8w6e",
    "outputId": "2e63ad1f-8e82-48b6-df3c-8be757384d04"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/goelprat/miniconda3/envs/fastai/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "--2fadnJ8w6l"
   },
   "outputs": [],
   "source": [
    "x_test = run_classification([x for x in testdf.sent], gpt_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qdLbrggv8w6n"
   },
   "outputs": [],
   "source": [
    "y_test = testdf.isvalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KYtmIuPC8w6q",
    "outputId": "180d6eaf-10f0-46e2-a2d7-64fcaf8d2b4a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.591044037605146"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BGsTmQ1m8w6v"
   },
   "source": [
    "Now, I try to find examples that are incorrectly classified by my GPT-2 based model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KMlL0lQV8w6y"
   },
   "outputs": [],
   "source": [
    "test_answers = pd.read_csv('/content/drive/My Drive/Colab Notebooks/data/trial/taskA_trial_answer.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jLrwcf928w60",
    "outputId": "c17180a4-1212-4276-8502-182707dfd5ba"
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ytrk2h2_8w67"
   },
   "outputs": [],
   "source": [
    "wrong_examples = x_test[test_answers[1] != pd.Series(results)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l_O12LPL8w69"
   },
   "outputs": [],
   "source": [
    "items = []\n",
    "for row in wrong_examples.itertuples():\n",
    "    items.append({'id' : row.id, 'sent' : row.sent0})\n",
    "    items.append({'id' : row.id, 'sent' : row.sent1})\n",
    "wrongdf = pd.DataFrame(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "wBQYDP0K8w6_",
    "outputId": "b695002a-335d-4874-818a-21a077640250"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       a man can better see stars and the moon in day...\n",
       "1       a man can hardly see stars and the moon in day...\n",
       "2                                   I work 25 hours a day\n",
       "3                                    I work 8 hours a day\n",
       "4        I changed my direction when passing a crossroads\n",
       "                              ...                        \n",
       "1273                    Jim downloads music from the book\n",
       "1274              Bob goes to bed because he feels sleepy\n",
       "1275             Bob goes to work because he feels sleepy\n",
       "1276    people have to hold onto their hats because of...\n",
       "1277    people have to hold onto their shoes because o...\n",
       "Name: sent, Length: 1278, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrongdf.sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "colab_type": "code",
    "id": "a3WtdHQm8w7B",
    "outputId": "7c611ebe-116b-4666-ea3e-8a5f60e6f296"
   },
   "outputs": [],
   "source": [
    "with open('wrong_examples.txt', 'w') as f:\n",
    "    for s in wrongdf.sent:\n",
    "        f.write(str(s) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IWQvvFSF8w7F"
   },
   "source": [
    "## Finetuning BERT using transformers library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "2cde83d55edf427fa2fbf3e535beac09",
      "197df6e7f7724935994042f0dec842a4",
      "4903ddedfef04516b44f534517d07851",
      "46f014b39fad4d0f9dfdaec07c10df3e",
      "ef49a5d738ba4cbe8c5996a099f460ed",
      "584bead4df0943cbbd1663243d2bd679",
      "f1ac8a5b3f7e420b97d76fbd536b435b",
      "03d93305b3754704ac24e5d960c6c5e2"
     ]
    },
    "colab_type": "code",
    "id": "FBCgSLIm8w7J",
    "outputId": "9333bf5a-32b2-4432-d2a7-f4ff611f541e"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "def get_bert_inputs(df):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    token_type_ids = []\n",
    "    for i, row in df.iterrows():\n",
    "        tokendict = tokenizer.encode_plus(row['sent0'], row['sent1'], max_length=50, pad_to_max_length=True)\n",
    "        input_ids.append(tokendict['input_ids'])\n",
    "        attention_masks.append(tokendict['attention_mask'])\n",
    "        token_type_ids.append(tokendict['token_type_ids'])\n",
    "    return torch.tensor(input_ids), torch.tensor(attention_masks), torch.tensor(token_type_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "avTpiHBQ8w7L"
   },
   "outputs": [],
   "source": [
    "input_ids, attention_masks, token_type_ids = get_bert_inputs(xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_dev, attention_masks_dev, token_type_ids_dev = get_bert_inputs(xydev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Un5JbKlK8w7N"
   },
   "outputs": [],
   "source": [
    "input_ids_test, attention_masks_test, token_type_ids_test = get_bert_inputs(xytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Pj49Yyc8w7O"
   },
   "outputs": [],
   "source": [
    "class MyBertForSequenceClassification(torch.nn.Module):  \n",
    "    def __init__(self, num_labels=1):\n",
    "        super(MyBertForSequenceClassification, self).__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.bert = BertForSequenceClassification.from_pretrained('bert-large-uncased')\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
    "        pooled_output = self.bert(input_ids, token_type_ids, attention_mask)\n",
    "        return pooled_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xrv_xa5K8w7Q"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
    "max_seq_length = 50\n",
    "class text_dataset(Dataset):\n",
    "    def __init__(self,x_y_list):\n",
    "        self.x_y_list = x_y_list\n",
    "        \n",
    "    def __getitem__(self,index):           \n",
    "        input_ids = self.x_y_list[0][index]\n",
    "        token_type_ids = self.x_y_list[1][index]\n",
    "        attention_mask = self.x_y_list[2][index]\n",
    "        label = self.x_y_list[3][index]\n",
    "        return input_ids, token_type_ids, attention_mask, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x_y_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gjHGz8x68w7T"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, device, num_epochs=25):\n",
    "    since = time.time()\n",
    "    print('starting')\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 100\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                print(\"VALIDATION\")\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            corrects = 0\n",
    "                        \n",
    "            # Iterate over data.\n",
    "            for inputs, token_types, mask, target in dataloaders_dict[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                token_types = token_types.to(device)\n",
    "                mask = mask.to(device)\n",
    "                target = target.to(device)\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs, token_type_ids=token_types, attention_mask=mask)\n",
    "                    outputs = F.softmax(outputs,dim=1)  \n",
    "                    loss = criterion(outputs, target)\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':                        \n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        scheduler.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                #print('Running loss : {:.4f}'.format(running_loss))\n",
    "                corrects += torch.sum(torch.max(outputs, 1)[1] == target)\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            acc = corrects.double() / dataset_sizes[phase]\n",
    "            print('{} total loss: {:.4f} '.format(phase,epoch_loss ))\n",
    "            print('{} accuracy: {:.4f}'.format(\n",
    "                phase, acc))\n",
    "\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                print('saving with loss of {}'.format(epoch_loss),\n",
    "                      'improved over previous {}'.format(best_loss))\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save(model.state_dict(), 'bert_model_test.pth')\n",
    "                \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    #print('Best val Acc: {:4f}'.format(float(best_loss)))\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P9Y3-7Dl8w7V"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "batch_size = 16\n",
    "invalid = torch.tensor(xy.invalid_sent)\n",
    "invalid_dev = torch.tensor(xydev.invalid_sent)\n",
    "#train_indices, val_indices = train_test_split([i for i in range(10000)])\n",
    "#train_lists = [input_ids[train_indices], token_type_ids[train_indices], attention_masks[train_indices], invalid[train_indices]]\n",
    "#val_lists = [input_ids[val_indices], token_type_ids[val_indices], attention_masks[val_indices], invalid[val_indices]]\n",
    "train_lists = [input_ids, token_type_ids, attention_masks, invalid]\n",
    "val_lists = [input_ids_dev, token_type_ids_dev, attention_masks_dev, invalid_dev]\n",
    "test_lists = [input_ids_test, token_type_ids_test, attention_masks_test, invalid]\n",
    "training_dataset = text_dataset(x_y_list = train_lists)\n",
    "val_dataset = text_dataset(x_y_list = val_lists)\n",
    "test_dataset = text_dataset(x_y_list = test_lists)\n",
    "\n",
    "dataloaders_dict = {'train': torch.utils.data.DataLoader(training_dataset, batch_size=batch_size, shuffle=True, num_workers=0),\n",
    "                   'val':torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "                   }\n",
    "dataset_sizes = {'train':len(train_lists[0]),\n",
    "                'val':len(val_lists[0])}\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "asghP-Ji_ES-",
    "outputId": "3a853891-3f1f-41dd-a102-885e2ddaa919"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_lists[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "0c13faf3c61d4e739b43d3b2e2b0e4a2",
      "1e07d8379d064f7c8fef772afe0a7ac2",
      "a7f9ba7b72ca4e9fbfd1995f9f046cf7",
      "a564e74ce99b414bb2b3a288370abae0",
      "b263c5db98604c4195acaddc8815fa88",
      "67b267518b1a46b4ad81f50797c1c6e1",
      "049d01a118444e5aaf684d467c0d07a6",
      "4c5f563401e840da9afd13fea555d516",
      "00492598dbd542c8a84592a5ac065991",
      "35cdabdbef024a6b81331ea10c614365",
      "5b56c4372bcb459ea8418eeabc92d7fc",
      "58ecfe855eef4271912a91187990e6fb",
      "26c778e84160499eaff2f073b05eec3b",
      "931405db76534b1db2a3a82103385cbf",
      "f85cef55a5724c5ab574f1c09f770d82",
      "663b3f4172b94ca98738f24923b0fc02"
     ]
    },
    "colab_type": "code",
    "id": "cPEvNpXg8w7X",
    "outputId": "86c908e9-d49c-4afd-8fb3-28dff2d46aa8"
   },
   "outputs": [],
   "source": [
    "model = MyBertForSequenceClassification().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a049Q2CV8w7b"
   },
   "outputs": [],
   "source": [
    "#from torch import optim\n",
    "from transformers.optimization import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "epochs = 3\n",
    "lrlast = .001\n",
    "lrmain = 2e-5\n",
    "optim = AdamW(model.bert.parameters(), lr=lrmain, eps=1e-8)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optim, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = (len(train_lists[0]) / batch_size) * epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "YAuAqzJB8w7e",
    "outputId": "afbd6ecb-2a60-484d-9fce-b15c8a8688cd",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting\n",
      "Epoch 0/2\n",
      "----------\n",
      "train total loss: 0.6208 \n",
      "train accuracy: 0.6521\n",
      "VALIDATION\n",
      "val total loss: 0.5578 \n",
      "val accuracy: 0.7422\n",
      "saving with loss of 0.5577636059810788 improved over previous 100\n",
      "Epoch 1/2\n",
      "----------\n",
      "train total loss: 0.4933 \n",
      "train accuracy: 0.8118\n",
      "VALIDATION\n",
      "val total loss: 0.5051 \n",
      "val accuracy: 0.7974\n",
      "saving with loss of 0.5051305820136037 improved over previous 0.5577636059810788\n",
      "Epoch 2/2\n",
      "----------\n",
      "train total loss: 0.4240 \n",
      "train accuracy: 0.8858\n",
      "VALIDATION\n",
      "val total loss: 0.5033 \n",
      "val accuracy: 0.8074\n",
      "saving with loss of 0.503279189587596 improved over previous 0.5051305820136037\n",
      "Training complete in 36m 6s\n"
     ]
    }
   ],
   "source": [
    "model_ft1 = train_model(model, criterion, optim, scheduler, device, num_epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cVuTH6_08w7g"
   },
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, num_workers=0)\n",
    "results = []\n",
    "for ipt, toktypes, maskt, targett in test_loader:\n",
    "    ipt = ipt.to(device)\n",
    "    toktypes = toktypes.to(device)\n",
    "    maskt = maskt.to(device)\n",
    "    outputs = model_ft1(ipt, toktypes, maskt)\n",
    "    outputs = F.softmax(outputs,dim=1)\n",
    "    for i in range(len(outputs)):\n",
    "        predicted_index = torch.argmax(outputs[i]).item()\n",
    "        results.append(predicted_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tQ_1LpCS8w7i",
    "outputId": "e7d116d7-24ae-4916-ee1b-74fc2103341d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2021"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rtfNuoys8w7k",
    "outputId": "387c8db6-6b92-470f-d200-3c4ffa31753c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 73.6764%\r\n"
     ]
    }
   ],
   "source": [
    "pd.concat([x_test.id, pd.Series(results)], axis=1).to_csv('./predictions.csv', header=False, index=False)\n",
    "!python3 eval/taskA_scorer.py --gold-labels data/trial/taskA_trial_answer.csv --pred-labels predictions.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OilIrc-GZ6L9"
   },
   "outputs": [],
   "source": [
    "test_answers = pd.read_csv('data/trial/taskA_trial_answer.csv', header=None)\n",
    "wrong_examples = x_test[test_answers[1] != pd.Series(results)]\n",
    "items = []\n",
    "for row in wrong_examples.itertuples():\n",
    "    items.append({'id' : row.id, 'sent' : row.sent0})\n",
    "    items.append({'id' : row.id, 'sent' : row.sent1})\n",
    "wrongdf = pd.DataFrame(items)\n",
    "with open('wrong_examples.txt', 'w') as f:\n",
    "    for s in wrongdf.sent:\n",
    "        f.write(str(s) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JNPogkrF2I1u"
   },
   "source": [
    "# Finetuning RoBERTa using [CLS] embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2eCNccjw30UU"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import RobertaTokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n",
    "def get_bert_inputs(df):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    for i, row in df.iterrows():\n",
    "        tokendict = tokenizer.encode_plus(row['sent0'], row['sent1'], max_length=50, pad_to_max_length=True)\n",
    "        input_ids.append(tokendict['input_ids'])\n",
    "        attention_masks.append(tokendict['attention_mask'])\n",
    "    return torch.tensor(input_ids), torch.tensor(attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TwnEq2HQ3-Qj"
   },
   "outputs": [],
   "source": [
    "input_ids, attention_masks = get_bert_inputs(xy)\n",
    "input_ids_dev, attention_masks_dev = get_bert_inputs(xydev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XcLBnYOz2HL8"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers import RobertaForSequenceClassification\n",
    "class MyRoBertaForSequenceClassification(nn.Module):\n",
    "  \n",
    "    def __init__(self, num_labels=1):\n",
    "        super(MyRoBertaForSequenceClassification, self).__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.bert = RobertaForSequenceClassification.from_pretrained('roberta-base')\n",
    "        #self.classifier = nn.Linear(768, num_labels)\n",
    "        #nn.init.xavier_normal_(self.classifier.weight)\n",
    "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
    "        pooled_output = self.bert(input_ids, attention_mask)\n",
    "        return pooled_output[0]\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MyRoBertaForSequenceClassification().to(device)\n",
    "#model = RobertaForSequenceClassification.from_pretrained('roberta-base')\n",
    "#model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rtr2PCkB6Qbn"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
    "max_seq_length = 50\n",
    "class text_dataset(Dataset):\n",
    "    def __init__(self,x_y_list):\n",
    "        self.x_y_list = x_y_list\n",
    "        \n",
    "    def __getitem__(self,index):           \n",
    "        input_ids = self.x_y_list[0][index]\n",
    "        attention_mask = self.x_y_list[1][index]\n",
    "        label = self.x_y_list[2][index]\n",
    "        return input_ids, attention_mask, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x_y_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jfD4fTgt3QTK"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "invalid = torch.tensor(xy.invalid_sent)\n",
    "invalid_dev = torch.tensor(xydev.invalid_sent)\n",
    "train_lists = [input_ids, attention_masks, invalid]\n",
    "val_lists = [input_ids_dev, attention_masks_dev, invalid_dev]\n",
    "\n",
    "training_dataset = text_dataset(x_y_list = train_lists)\n",
    "val_dataset = text_dataset(x_y_list = val_lists)\n",
    "\n",
    "dataloaders_dict = {'train': torch.utils.data.DataLoader(training_dataset, batch_size=batch_size, shuffle=True, num_workers=0),\n",
    "                   'val':torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "                   }\n",
    "dataset_sizes = {'train':len(train_lists[0]),\n",
    "                'val':len(val_lists[0])}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, device, num_epochs=25, phases=['train', 'val']):\n",
    "    since = time.time()\n",
    "    print('starting')\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 100\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in phases:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                print(\"VALIDATION\")\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            corrects = 0\n",
    "                        \n",
    "            # Iterate over data.\n",
    "            for inputs, mask, target in dataloaders_dict[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                mask = mask.to(device)\n",
    "                target = target.to(device)\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs, attention_mask=mask)\n",
    "                    #import pdb; pdb.set_trace()\n",
    "                    outputs = F.softmax(outputs,dim=1)  \n",
    "                    loss = criterion(outputs, target)\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':                        \n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        scheduler.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                #print('Running loss : {:.4f}'.format(running_loss))\n",
    "                corrects += torch.sum(torch.max(outputs, 1)[1] == target)\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            acc = corrects.double() / dataset_sizes[phase]\n",
    "            print('{} total loss: {:.4f} '.format(phase,epoch_loss ))\n",
    "            print('{} accuracy: {:.4f}'.format(\n",
    "                phase, acc))\n",
    "\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                print('saving with loss of {}'.format(epoch_loss),\n",
    "                      'improved over previous {}'.format(best_loss))\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save(model.state_dict(), 'bert_model_test.pth')\n",
    "                \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    #print('Best val Acc: {:4f}'.format(float(best_loss)))\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eye5z2tC4b72"
   },
   "outputs": [],
   "source": [
    "#from torch import optim\n",
    "from transformers.optimization import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "batch_size = 16\n",
    "epochs = 3\n",
    "lrlast = .001\n",
    "lrmain = 2e-5\n",
    "optim = AdamW(model.bert.parameters(), lr=lrmain, eps=1e-8)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optim, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = (len(train_lists[0]) / batch_size) * epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_lists[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "JEOTAQYh4djx",
    "outputId": "b5ac1a53-39fd-4316-f1a6-4fca31f9ab7e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting\n",
      "Epoch 0/2\n",
      "----------\n",
      "train total loss: 0.6948 \n",
      "train accuracy: 0.4889\n",
      "VALIDATION\n",
      "val total loss: 0.6947 \n",
      "val accuracy: 0.4804\n",
      "saving with loss of 0.6946904892428828 improved over previous 100\n",
      "Epoch 1/2\n",
      "----------\n",
      "train total loss: 0.6141 \n",
      "train accuracy: 0.6624\n",
      "VALIDATION\n",
      "val total loss: 0.5119 \n",
      "val accuracy: 0.7924\n",
      "saving with loss of 0.5119188002263053 improved over previous 0.6946904892428828\n",
      "Epoch 2/2\n",
      "----------\n",
      "train total loss: 0.4871 \n",
      "train accuracy: 0.8126\n",
      "VALIDATION\n",
      "val total loss: 0.4781 \n",
      "val accuracy: 0.8215\n",
      "saving with loss of 0.4781279314604542 improved over previous 0.5119188002263053\n",
      "Training complete in 11m 34s\n"
     ]
    }
   ],
   "source": [
    "model_ft1 = train_model(model, criterion, optim, scheduler, device, num_epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting\n",
      "Epoch 0/0\n",
      "----------\n",
      "VALIDATION\n",
      "val total loss: 0.6932 \n",
      "val accuracy: 0.5064\n",
      "saving with loss of 0.6932363882064819 improved over previous 100\n",
      "Training complete in 0m 21s\n"
     ]
    }
   ],
   "source": [
    "model_ft1 = train_model(model, criterion, optim, scheduler, device, num_epochs=1, phases=['val'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p9DSmNjr6kg7"
   },
   "outputs": [],
   "source": [
    "invalid_test = torch.tensor(xytest.invalid_sent)\n",
    "input_ids_test, attention_masks_test = get_bert_inputs(xytest)\n",
    "test_lists = [input_ids_test, attention_masks_test, invalid_test]\n",
    "test_dataset = text_dataset(x_y_list = test_lists)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, num_workers=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_results(data_loader):\n",
    "    results = []\n",
    "    for ipt, maskt, targett in data_loader:\n",
    "        ipt = ipt.to(device)\n",
    "        maskt = maskt.to(device)\n",
    "        outputs = model_ft1(ipt, maskt)\n",
    "        outputs = F.softmax(outputs,dim=1)\n",
    "        for i in range(len(outputs)):\n",
    "            predicted_index = torch.argmax(outputs[i]).item()\n",
    "            results.append(predicted_index)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = generate_results(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FT993iY96tfL",
    "outputId": "9d52638d-d82d-441d-d772-0eaf77420202"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.8877%\r\n"
     ]
    }
   ],
   "source": [
    "pd.concat([x_test.id, pd.Series(results)], axis=1).to_csv('./predictions.csv', header=False, index=False)\n",
    "!python3 eval/taskA_scorer.py --gold-labels data/trial/taskA_trial_answer.csv --pred-labels predictions.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_eval = pd.read_csv('data/test/subtaskA_test_data.csv')\n",
    "input_ids_eval, attention_masks_eval = get_bert_inputs(x_eval)\n",
    "eval_lists = [input_ids_eval, attention_masks_eval, invalid]\n",
    "eval_dataset = text_dataset(x_y_list = eval_lists)\n",
    "eval_loader = torch.utils.data.DataLoader(eval_dataset, batch_size=batch_size, num_workers=0)\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = generate_results(eval_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([x_eval.id, pd.Series(results)], axis=1).to_csv('./predictions.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LMMmk_m37GOm"
   },
   "outputs": [],
   "source": [
    "test_answers = pd.read_csv('data/trial/taskA_trial_answer.csv', header=None)\n",
    "wrong_examples = x_test[test_answers[1] != pd.Series(results)]\n",
    "items = []\n",
    "for row in wrong_examples.itertuples():\n",
    "    items.append({'id' : row.id, 'sent' : row.sent0})\n",
    "    items.append({'id' : row.id, 'sent' : row.sent1})\n",
    "wrongdf = pd.DataFrame(items)\n",
    "with open('wrong_examples.txt', 'w') as f:\n",
    "    for s in wrongdf.sent:\n",
    "        f.write(str(s) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using LSTM to get sentence embedding from RoBERTa embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from transformers import RobertaModel\n",
    "class CommonSenseClassifier(nn.Module):\n",
    "    \"\"\"Container module with an encoder, a recurrent module, and a decoder.\"\"\"\n",
    "\n",
    "    def __init__(self, rnn_type, ninp, nhid, nlayers, dropout=0.5):\n",
    "        super(CommonSenseClassifier, self).__init__()\n",
    "        #self.ntoken = ntoken\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        #self.encoder = nn.Embedding(ntoken, ninp)\n",
    "        if rnn_type in ['LSTM', 'GRU']:\n",
    "            self.rnn1 = getattr(nn, rnn_type)(ninp, nhid, nlayers, dropout=dropout)\n",
    "            self.rnn2 = getattr(nn, rnn_type)(ninp, nhid, nlayers, dropout=dropout)\n",
    "        else:\n",
    "            try:\n",
    "                nonlinearity = {'RNN_TANH': 'tanh', 'RNN_RELU': 'relu'}[rnn_type]\n",
    "            except KeyError:\n",
    "                raise ValueError( \"\"\"An invalid option for `--model` was supplied,\n",
    "                                 options are ['LSTM', 'GRU', 'RNN_TANH' or 'RNN_RELU']\"\"\")\n",
    "            self.rnn = nn.RNN(ninp, nhid, nlayers, nonlinearity=nonlinearity, dropout=dropout)\n",
    "        self.lin1 = nn.Linear(ninp, 1)\n",
    "        self.lin2 = nn.Linear(ninp, 1)\n",
    "        self.classifier = nn.Linear(2, 2)\n",
    "        nn.init.xavier_normal_(self.lin1.weight)\n",
    "        nn.init.xavier_normal_(self.lin2.weight)\n",
    "        nn.init.xavier_normal_(self.classifier.weight)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "        self.rnn_type = rnn_type\n",
    "        self.nhid = nhid\n",
    "        self.nlayers = nlayers\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        #self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.classifier.bias.data.zero_()\n",
    "        self.classifier.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, input1, input2, hidden1, hidden2):\n",
    "        #emb = self.drop(self.encoder(input))\n",
    "        #emb = self.drop(input)\n",
    "        output1, hidden1 = self.rnn1(input1, hidden1)\n",
    "        output2, hidden2 = self.rnn2(input2, hidden2)\n",
    "        #output = self.drop(output)\n",
    "        #decoded = self.decoder(output)\n",
    "        #decoded = decoded.view(-1, self.ntoken)\n",
    "        #return F.log_softmax(decoded, dim=1), hidden\n",
    "        cell1 = hidden1[1].squeeze()\n",
    "        cell2 = hidden2[1].squeeze()\n",
    "        out1 = self.lin1(cell1)\n",
    "        out2 = self.lin2(cell2)\n",
    "        #class_features = torch.cat((cell1, cell2), 1)\n",
    "        #import pdb; pdb.set_trace()\n",
    "        output = torch.cat((out1, out2), 1)\n",
    "        return torch.nn.functional.softmax(output, dim=1), hidden1, hidden2\n",
    "\n",
    "    def init_hidden(self, bsz):\n",
    "        weight = next(self.parameters())\n",
    "        if self.rnn_type == 'LSTM':\n",
    "            return (weight.new_zeros(self.nlayers, bsz, self.nhid),\n",
    "                    weight.new_zeros(self.nlayers, bsz, self.nhid))\n",
    "        else:\n",
    "            return weight.new_zeros(self.nlayers, bsz, self.nhid)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "bert = RobertaModel.from_pretrained('roberta-base')\n",
    "bert = bert.to(device)\n",
    "sense_model = CommonSenseClassifier('LSTM', 768, 768, 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_toks = 0\n",
    "for i, row in xytest.iterrows():\n",
    "    ntokens = len(row['sent0'].split())\n",
    "    if ntokens > max_toks:\n",
    "        max_toks = ntokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce89a2f2a9844a238d97fb33b99664f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30eed4da95b347538d8e6e9e5d73e001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import RobertaTokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "max_seq_length = 25\n",
    "def get_roberta_inputs(df):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    for i, row in df.iterrows():\n",
    "\n",
    "        tokendict1 = tokenizer.encode_plus(row['sent0'], max_length=max_seq_length, pad_to_max_length=True, add_special_tokens=False)\n",
    "        tokendict2 = tokenizer.encode_plus(row['sent1'], max_length=max_seq_length, pad_to_max_length=True, add_special_tokens=False)\n",
    "        input_ids.append((tokendict1['input_ids'], tokendict2['input_ids']))\n",
    "        attention_masks.append((tokendict1['attention_mask'], tokendict2['attention_mask']))\n",
    "    return torch.tensor(input_ids), torch.tensor(attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "class text_dataset(Dataset):\n",
    "    def __init__(self,x_y_list):\n",
    "        self.x_y_list = x_y_list\n",
    "        \n",
    "    def __getitem__(self,index):           \n",
    "        input_ids = self.x_y_list[0][index]\n",
    "        attention_mask = self.x_y_list[1][index]\n",
    "        label = self.x_y_list[2][index]\n",
    "        return input_ids, attention_mask, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x_y_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xy = xy[:100]\n",
    "#xydev = xydev[:20]\n",
    "input_ids, attention_masks = get_roberta_inputs(xy)\n",
    "input_ids_dev, attention_masks_dev = get_roberta_inputs(xydev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 2, 25])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "batch_size = 16\n",
    "epochs = 20\n",
    "invalid = torch.tensor(xy.invalid_sent)\n",
    "invalid_dev = torch.tensor(xydev.invalid_sent)\n",
    "train_indices, val_indices = train_test_split([i for i in range(10000)])\n",
    "#train_lists = [input_ids[train_indices], attention_masks[train_indices], invalid[train_indices]]\n",
    "#val_lists = [input_ids[val_indices], attention_masks[val_indices], invalid[val_indices]]\n",
    "train_lists = [input_ids, attention_masks, invalid]\n",
    "val_lists = [input_ids_dev, attention_masks_dev, invalid_dev]\n",
    "\n",
    "training_dataset = text_dataset(x_y_list = train_lists)\n",
    "val_dataset = text_dataset(x_y_list = val_lists)\n",
    "\n",
    "dataloaders_dict = {'train': torch.utils.data.DataLoader(training_dataset, batch_size=batch_size, shuffle=True, num_workers=0),\n",
    "                   'val':torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "                   }\n",
    "dataset_sizes = {'train':len(train_lists[0]),\n",
    "                'val':len(val_lists[0])}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torch import optim\n",
    "from torch.optim import Adam\n",
    "from torch.optim import lr_scheduler\n",
    "max_lr = 0.001\n",
    "lrmain = 2e-5\n",
    "optim = Adam(sense_model.parameters(), lr=lrmain, eps=1e-8)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = lr_scheduler.OneCycleLR(optim, max_lr=max_lr, total_steps = int((len(train_lists[0]) / batch_size) * epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2e-05"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrmain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repackage_hidden(h):\n",
    "    \"\"\"Wraps hidden states in new Tensors, to detach them from their history.\"\"\"\n",
    "\n",
    "    if isinstance(h, torch.Tensor):\n",
    "        return h.detach()\n",
    "    else:\n",
    "        return tuple(repackage_hidden(v) for v in h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "\n",
    "def train(model, criterion, optimizer, scheduler, device, num_epochs=25, phases=['train', 'val']):\n",
    "    since = time.time()\n",
    "    print('starting')\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 100\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch %d\" % epoch)\n",
    "        model.train()  # Set model to training mode\n",
    "        #running_loss = 0.0\n",
    "        # Iterate over data.\n",
    "        for phase in phases:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                print(\"VALIDATION\")\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            corrects = 0\n",
    "            for inputs, mask, target in dataloaders_dict[phase]:\n",
    "                inputs = inputs.to(device)            # batch_size x max_sent_len\n",
    "                mask = mask.to(device)\n",
    "                target = target.to(device)\n",
    "                hidden1 = model.init_hidden(inputs.size(0))\n",
    "                hidden2 = model.init_hidden(inputs.size(0))\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(False):\n",
    "                    bert_outputs = bert(inputs.reshape((inputs.size(0) * 2, max_seq_length)), attention_mask=mask.reshape((inputs.size(0) * 2, max_seq_length)))\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    embeddings = bert_outputs[0].permute(1, 0, 2)\n",
    "                    emb1 = embeddings[:, ::2, :]\n",
    "                    emb2 = embeddings[:, 1::2, :]\n",
    "                    #hidden = model.init_hidden(inputs.size(0))\n",
    "                    #hidden = repackage_hidden(hidden)\n",
    "                    logits, h1, h2 = model(emb1, emb2, hidden1, hidden2)\n",
    "                    loss = criterion(logits, target)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        scheduler.step()\n",
    "\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    corrects += torch.sum(torch.max(logits, 1)[1] == target)\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            acc = corrects.double() / dataset_sizes[phase]\n",
    "            print('{} total loss: {:.4f} '.format(phase,epoch_loss ))\n",
    "            print('{} accuracy: {:.4f}'.format(\n",
    "                phase, acc))\n",
    "\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                print('saving with loss of {}'.format(epoch_loss),\n",
    "                      'improved over previous {}'.format(best_loss))\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save(model.state_dict(), 'bert_model_test.pth')\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    #print('Best val Acc: {:4f}'.format(float(best_loss)))\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting\n",
      "Epoch 0\n",
      "train total loss: 0.4945 \n",
      "train accuracy: 0.8088\n",
      "VALIDATION\n",
      "val total loss: 0.5606 \n",
      "val accuracy: 0.7392\n",
      "saving with loss of 0.5605972791268091 improved over previous 100\n",
      "Epoch 1\n",
      "train total loss: 0.4784 \n",
      "train accuracy: 0.8259\n",
      "VALIDATION\n",
      "val total loss: 0.5562 \n",
      "val accuracy: 0.7462\n",
      "saving with loss of 0.556222177077918 improved over previous 0.5605972791268091\n",
      "Epoch 2\n",
      "train total loss: 0.4620 \n",
      "train accuracy: 0.8460\n",
      "VALIDATION\n",
      "val total loss: 0.5557 \n",
      "val accuracy: 0.7462\n",
      "saving with loss of 0.5557334069442844 improved over previous 0.556222177077918\n",
      "Epoch 3\n",
      "train total loss: 0.4486 \n",
      "train accuracy: 0.8603\n",
      "VALIDATION\n",
      "val total loss: 0.5712 \n",
      "val accuracy: 0.7212\n",
      "Epoch 4\n",
      "train total loss: 0.4379 \n",
      "train accuracy: 0.8699\n",
      "VALIDATION\n",
      "val total loss: 0.5971 \n",
      "val accuracy: 0.7041\n",
      "Epoch 5\n",
      "train total loss: 0.4221 \n",
      "train accuracy: 0.8891\n",
      "VALIDATION\n",
      "val total loss: 0.5680 \n",
      "val accuracy: 0.7212\n",
      "Epoch 6\n",
      "train total loss: 0.4140 \n",
      "train accuracy: 0.8967\n",
      "VALIDATION\n",
      "val total loss: 0.5522 \n",
      "val accuracy: 0.7543\n",
      "saving with loss of 0.5522147106789538 improved over previous 0.5557334069442844\n",
      "Epoch 7\n",
      "train total loss: 0.3954 \n",
      "train accuracy: 0.9159\n",
      "VALIDATION\n",
      "val total loss: 0.5577 \n",
      "val accuracy: 0.7402\n",
      "Epoch 8\n",
      "train total loss: 0.3806 \n",
      "train accuracy: 0.9318\n",
      "VALIDATION\n",
      "val total loss: 0.5752 \n",
      "val accuracy: 0.7322\n",
      "Epoch 9\n",
      "train total loss: 0.3700 \n",
      "train accuracy: 0.9430\n",
      "VALIDATION\n",
      "val total loss: 0.5668 \n",
      "val accuracy: 0.7322\n",
      "Epoch 10\n",
      "train total loss: 0.3616 \n",
      "train accuracy: 0.9514\n",
      "VALIDATION\n",
      "val total loss: 0.5600 \n",
      "val accuracy: 0.7432\n",
      "Epoch 11\n",
      "train total loss: 0.3555 \n",
      "train accuracy: 0.9578\n",
      "VALIDATION\n",
      "val total loss: 0.5603 \n",
      "val accuracy: 0.7422\n",
      "Epoch 12\n",
      "train total loss: 0.3473 \n",
      "train accuracy: 0.9667\n",
      "VALIDATION\n",
      "val total loss: 0.5451 \n",
      "val accuracy: 0.7583\n",
      "saving with loss of 0.545068196212516 improved over previous 0.5522147106789538\n",
      "Epoch 13\n",
      "train total loss: 0.3427 \n",
      "train accuracy: 0.9708\n",
      "VALIDATION\n",
      "val total loss: 0.5478 \n",
      "val accuracy: 0.7613\n",
      "Epoch 14\n",
      "train total loss: 0.3407 \n",
      "train accuracy: 0.9729\n",
      "VALIDATION\n",
      "val total loss: 0.5457 \n",
      "val accuracy: 0.7633\n",
      "Epoch 15\n",
      "train total loss: 0.3387 \n",
      "train accuracy: 0.9746\n",
      "VALIDATION\n",
      "val total loss: 0.5402 \n",
      "val accuracy: 0.7663\n",
      "saving with loss of 0.5401988688299625 improved over previous 0.545068196212516\n",
      "Epoch 16\n",
      "train total loss: 0.3376 \n",
      "train accuracy: 0.9758\n",
      "VALIDATION\n",
      "val total loss: 0.5477 \n",
      "val accuracy: 0.7523\n",
      "Epoch 17\n",
      "train total loss: 0.3371 \n",
      "train accuracy: 0.9762\n",
      "VALIDATION\n",
      "val total loss: 0.5440 \n",
      "val accuracy: 0.7623\n",
      "Epoch 18\n",
      "train total loss: 0.3368 \n",
      "train accuracy: 0.9765\n",
      "VALIDATION\n",
      "val total loss: 0.5452 \n",
      "val accuracy: 0.7613\n",
      "Epoch 19\n",
      "train total loss: 0.3366 \n",
      "train accuracy: 0.9767\n",
      "VALIDATION\n",
      "val total loss: 0.5454 \n",
      "val accuracy: 0.7603\n",
      "Training complete in 32m 59s\n"
     ]
    }
   ],
   "source": [
    "model_ft1 = train(sense_model, criterion, optim, scheduler, device, num_epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_test = torch.tensor(xytest.invalid_sent)\n",
    "input_ids_test, attention_masks_test = get_roberta_inputs(xytest)\n",
    "test_lists = [input_ids_test, attention_masks_test, invalid_test]\n",
    "test_dataset = text_dataset(x_y_list = test_lists)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, num_workers=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_results(model, data_loader):\n",
    "    results = []\n",
    "    for ipt, maskt, targett in data_loader:\n",
    "        hidden1 = model.init_hidden(ipt.size(0))\n",
    "        hidden2 = model.init_hidden(ipt.size(0))\n",
    "        ipt = ipt.to(device)\n",
    "        maskt = maskt.to(device)\n",
    "        bert_outputs = bert(ipt.reshape((ipt.size(0) * 2, max_seq_length)), attention_mask=maskt.reshape((ipt.size(0) * 2, max_seq_length)))\n",
    "        embeddings = bert_outputs[0].permute(1, 0, 2)\n",
    "        emb1 = embeddings[:, ::2, :]\n",
    "        emb2 = embeddings[:, 1::2, :]\n",
    "        logits, h1, h2 = model(emb1, emb2, hidden1, hidden2)\n",
    "        for i in range(len(logits)):\n",
    "            predicted_index = torch.argmax(logits[i]).item()\n",
    "            results.append(predicted_index)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = generate_results(sense_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.5854%\r\n"
     ]
    }
   ],
   "source": [
    "pd.concat([x_test.id, pd.Series(results)], axis=1).to_csv('./predictions.csv', header=False, index=False)\n",
    "!python3 eval/taskA_scorer.py --gold-labels data/trial/taskA_trial_answer.csv --pred-labels predictions.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning RoBERTa using all token embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (2.9.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (3.0.4)\n",
      "Requirement already satisfied: sentencepiece in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (0.1.86)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (4.42.1)\n",
      "Requirement already satisfied: sacremoses in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (2.20.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (1.15.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (2020.5.7)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (0.6)\n",
      "Requirement already satisfied: tokenizers==0.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sacremoses->transformers) (1.11.0)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sacremoses->transformers) (6.7)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->transformers) (1.23)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->transformers) (2.6)\n",
      "\u001b[31mfastai 1.0.60 requires nvidia-ml-py3, which is not installed.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import RobertaTokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "def get_roberta_inputs(df):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    for i, row in df.iterrows():\n",
    "        tokendict = tokenizer.encode_plus(row['sent0'], row['sent1'], max_length=50, pad_to_max_length=True)\n",
    "        input_ids.append(tokendict['input_ids'])\n",
    "        attention_masks.append(tokendict['attention_mask'])\n",
    "    return torch.tensor(input_ids), torch.tensor(attention_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids, attention_masks = get_roberta_inputs(xy)\n",
    "input_ids_dev, attention_masks_dev = get_roberta_inputs(xydev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
    "max_seq_length = 50\n",
    "class text_dataset(Dataset):\n",
    "    def __init__(self,x_y_list):\n",
    "        self.x_y_list = x_y_list\n",
    "        \n",
    "    def __getitem__(self,index):           \n",
    "        input_ids = self.x_y_list[0][index]\n",
    "        attention_mask = self.x_y_list[1][index]\n",
    "        label = self.x_y_list[2][index]\n",
    "        return input_ids, attention_mask, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x_y_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "batch_size = 16\n",
    "invalid = torch.tensor(xy.invalid_sent)\n",
    "invalid_dev = torch.tensor(xydev.invalid_sent)\n",
    "train_lists = [input_ids, attention_masks, invalid]\n",
    "val_lists = [input_ids_dev, attention_masks_dev, invalid_dev]\n",
    "\n",
    "training_dataset = text_dataset(x_y_list = train_lists)\n",
    "val_dataset = text_dataset(x_y_list = val_lists)\n",
    "\n",
    "dataloaders_dict = {'train': torch.utils.data.DataLoader(training_dataset, batch_size=batch_size, shuffle=True, num_workers=0),\n",
    "                   'val':torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "                   }\n",
    "dataset_sizes = {'train':len(train_lists[0]),\n",
    "                'val':len(val_lists[0])}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers import RobertaModel\n",
    "class CommonSenseClassifierV(nn.Module):\n",
    "  \n",
    "    def __init__(self, num_labels=2):\n",
    "        super(CommonSenseClassifierV, self).__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.bert = RobertaModel.from_pretrained('roberta-base')\n",
    "        self.classifier = nn.Linear(38400, num_labels)\n",
    "        nn.init.xavier_normal_(self.classifier.weight)\n",
    "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
    "        pooled_output = self.bert(input_ids, attention_mask)\n",
    "        embeddings = pooled_output[0].reshape(input_ids.size(0), max_seq_length * 768) #16 x 50 x 768 -> 16 x 38400\n",
    "        logits = self.classifier(embeddings)\n",
    "        return logits\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_V = CommonSenseClassifierV().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-config.json from cache at /home/ec2-user/.cache/torch/transformers/c22e0b5bbb7c0cb93a87a2ae01263ae715b4c18d692b1740ce72cacaa99ad184.2d28da311092e99a05f9ee17520204614d60b0bfdb32f8a75644df7737b6a748\n",
      "INFO:transformers.configuration_utils:Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/roberta-large-pytorch_model.bin from cache at /home/ec2-user/.cache/torch/transformers/2339ac1858323405dffff5156947669fed6f63a0c34cfab35bda4f78791893d2.fc7abf72755ecc4a75d0d336a93c1c63358d2334f5998ed326f3b0da380bf536\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from transformers import RobertaModel\n",
    "class CommonSenseClassifierVI(nn.Module):\n",
    "  \n",
    "    def __init__(self, num_labels=2):\n",
    "        super(CommonSenseClassifierVI, self).__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.bert = RobertaModel.from_pretrained('roberta-large', output_hidden_states=True)\n",
    "        self.classifier = nn.Linear(51200, 2)\n",
    "        #self.drop = nn.Dropout(0.2)\n",
    "        #self.classifier = nn.Linear(512, num_labels)\n",
    "        #nn.init.xavier_normal_(self.lin1.weight)\n",
    "        #nn.init.xavier_normal_(self.classifier.weight)\n",
    "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
    "        pooled_output = self.bert(input_ids, attention_mask)\n",
    "        embeddings = pooled_output[2][-1] * attention_mask.reshape(input_ids.size(0), max_seq_length, 1)\n",
    "        flattened_embeddings = embeddings.reshape(input_ids.size(0), max_seq_length * 1024) # batch_size x 51200\n",
    "        #import pdb; pdb.set_trace()\n",
    "        #embeddings = torch.cat((pooled_output[2][-1], pooled_output[2][-2]), 2)\n",
    "        #flattened_embeddings = embeddings.reshape(input_ids.size(0), max_seq_length * 1024 * 2)\n",
    "        logits = self.classifier(flattened_embeddings)\n",
    "        return logits\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_VI = CommonSenseClassifierVI().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, device, num_epochs=25, phases=['train', 'val']):\n",
    "    since = time.time()\n",
    "    print('starting')\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 100\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in phases:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                print(\"VALIDATION\")\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            corrects = 0\n",
    "                        \n",
    "            # Iterate over data.\n",
    "            for inputs, mask, target in dataloaders_dict[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                mask = mask.to(device)\n",
    "                target = target.to(device)\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs, attention_mask=mask)\n",
    "                    #import pdb; pdb.set_trace()\n",
    "                    outputs = F.softmax(outputs,dim=1)  \n",
    "                    loss = criterion(outputs, target)\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':                        \n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        scheduler.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                #print('Running loss : {:.4f}'.format(running_loss))\n",
    "                corrects += torch.sum(torch.max(outputs, 1)[1] == target)\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            acc = corrects.double() / dataset_sizes[phase]\n",
    "            print('{} total loss: {:.4f} '.format(phase,epoch_loss ))\n",
    "            print('{} accuracy: {:.4f}'.format(\n",
    "                phase, acc))\n",
    "\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                print('saving with loss of {}'.format(epoch_loss),\n",
    "                      'improved over previous {}'.format(best_loss))\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save(model.state_dict(), 'bert_model_test.pth')\n",
    "                \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    #print('Best val Acc: {:4f}'.format(float(best_loss)))\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torch import optim\n",
    "from transformers.optimization import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "epochs = 3\n",
    "lrlast = .001\n",
    "lrmain = 2e-5\n",
    "optim = AdamW(model_VI.parameters(), lr=lrmain, eps=1e-8)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optim, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = (len(train_lists[0]) / batch_size) * epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommonSenseClassifierVI(\n",
       "  (bert): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (12): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (13): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (14): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (15): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (16): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (17): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (18): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (19): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (20): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (21): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (22): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (23): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=51200, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_VI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting\n",
      "Epoch 0/2\n",
      "----------\n",
      "train total loss: 0.5243 \n",
      "train accuracy: 0.7566\n",
      "VALIDATION\n",
      "val total loss: 0.3937 \n",
      "val accuracy: 0.9168\n",
      "saving with loss of 0.39372699944640593 improved over previous 100\n",
      "Epoch 1/2\n",
      "----------\n",
      "train total loss: 0.3902 \n",
      "train accuracy: 0.9198\n",
      "VALIDATION\n",
      "val total loss: 0.3714 \n",
      "val accuracy: 0.9388\n",
      "saving with loss of 0.3714007577123709 improved over previous 0.39372699944640593\n",
      "Epoch 2/2\n",
      "----------\n",
      "train total loss: 0.3565 \n",
      "train accuracy: 0.9552\n",
      "VALIDATION\n",
      "val total loss: 0.3685 \n",
      "val accuracy: 0.9418\n",
      "saving with loss of 0.36848067137279145 improved over previous 0.3714007577123709\n",
      "Training complete in 35m 12s\n"
     ]
    }
   ],
   "source": [
    "model_ft1 = train_model(model_VI, criterion, optim, scheduler, device, num_epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_test = torch.tensor(xytest.invalid_sent)\n",
    "input_ids_test, attention_masks_test = get_roberta_inputs(xytest)\n",
    "test_lists = [input_ids_test, attention_masks_test, invalid_test]\n",
    "test_dataset = text_dataset(x_y_list = test_lists)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, num_workers=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_results(data_loader):\n",
    "    results = []\n",
    "    for ipt, maskt, targett in data_loader:\n",
    "        ipt = ipt.to(device)\n",
    "        maskt = maskt.to(device)\n",
    "        outputs = model_ft1(ipt, maskt)\n",
    "        outputs = F.softmax(outputs,dim=1)\n",
    "        for i in range(len(outputs)):\n",
    "            predicted_index = torch.argmax(outputs[i]).item()\n",
    "            results.append(predicted_index)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = generate_results(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.8357%\r\n"
     ]
    }
   ],
   "source": [
    "pd.concat([x_test.id, pd.Series(results)], axis=1).to_csv('./predictions.csv', header=False, index=False)\n",
    "!python3 eval/taskA_scorer.py --gold-labels data/trial/taskA_trial_answer.csv --pred-labels predictions.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_eval = pd.read_csv('data/test/subtaskA_test_data.csv')\n",
    "input_ids_eval, attention_masks_eval = get_roberta_inputs(x_eval)\n",
    "eval_lists = [input_ids_eval, attention_masks_eval, invalid]\n",
    "eval_dataset = text_dataset(x_y_list = eval_lists)\n",
    "eval_loader = torch.utils.data.DataLoader(eval_dataset, batch_size=batch_size, num_workers=0)\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = generate_results(eval_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([x_eval.id, pd.Series(results)], axis=1).to_csv('./subtaskA_answers.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_answers = pd.read_csv('data/trial/taskA_trial_answer.csv', header=None)\n",
    "wrong_examples = x_test[test_answers[1] != pd.Series(results)]\n",
    "items = []\n",
    "for row in wrong_examples.itertuples():\n",
    "    items.append({'id' : row.id, 'sent' : row.sent0})\n",
    "    items.append({'id' : row.id, 'sent' : row.sent1})\n",
    "wrongdf = pd.DataFrame(items)\n",
    "with open('wrong_examples.txt', 'w') as f:\n",
    "    for s in wrongdf.sent:\n",
    "        f.write(str(s) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_examples = x_test[test_answers[1] != pd.Series(results)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sent0</th>\n",
       "      <th>sent1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>83</td>\n",
       "      <td>he opens the door with a lock</td>\n",
       "      <td>he opens the door with a key</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>144</td>\n",
       "      <td>the Taj Mahal is made of white marbles</td>\n",
       "      <td>the Taj Mahal is made of white maples</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>150</td>\n",
       "      <td>Mongolia is mass surrounded by water</td>\n",
       "      <td>the UK is mass surrounded by water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>187</td>\n",
       "      <td>Harry jumps high to throw the basketball into ...</td>\n",
       "      <td>Harry stoops down to throw the basketball into...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>191</td>\n",
       "      <td>Maria coughs when she breathes in fresh air</td>\n",
       "      <td>Maria coughs when she breathes in haze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>217</td>\n",
       "      <td>Carter opened the window of the airplane to ge...</td>\n",
       "      <td>Carter opened the ventilator of the airplane t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>249</td>\n",
       "      <td>She sharpened the pencil with a knife</td>\n",
       "      <td>She sharpened the pencil with an eraser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>259</td>\n",
       "      <td>I should take off my trousers when swimming</td>\n",
       "      <td>I should take off my underpants when swimming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>270</td>\n",
       "      <td>a tiger is probable to beat a dog</td>\n",
       "      <td>a dog is probable to beat a tiger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>288</td>\n",
       "      <td>if we are going to be late we should walk</td>\n",
       "      <td>if we are going to be late we should run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>304</td>\n",
       "      <td>People are able to cheat</td>\n",
       "      <td>people are only able to be honest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>328</td>\n",
       "      <td>I will feel energetic after running</td>\n",
       "      <td>I will feel hungry after running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>332</td>\n",
       "      <td>people usually eat ice cream in summer</td>\n",
       "      <td>people usually eat ice cream in winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>333</td>\n",
       "      <td>we wear thick clothes in winter</td>\n",
       "      <td>we wear thin clothes in winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>334</td>\n",
       "      <td>we can see white clouds and dark clouds in the...</td>\n",
       "      <td>we can only see white clouds in the air</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>345</td>\n",
       "      <td>I can drink after driving</td>\n",
       "      <td>I can drive after drinking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>357</td>\n",
       "      <td>We communicate in the same language</td>\n",
       "      <td>We communicate in different languages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>371</td>\n",
       "      <td>today I will go to my hometowns</td>\n",
       "      <td>today I will go to my hometown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>372</td>\n",
       "      <td>My blood type is the same as some people.</td>\n",
       "      <td>My blood type is the same as everyone.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>386</td>\n",
       "      <td>Pushing a bike requires much strength</td>\n",
       "      <td>Pushing a car requires much strength</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>391</td>\n",
       "      <td>blind people can watch nothing</td>\n",
       "      <td>Blind people can watch the TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>392</td>\n",
       "      <td>A child will be a child forever</td>\n",
       "      <td>A child can become an adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>398</td>\n",
       "      <td>Something that might happen when you diminish ...</td>\n",
       "      <td>Something that might happen when you diminish ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>419</td>\n",
       "      <td>No living thing can live in the sea</td>\n",
       "      <td>some living things can live in the sea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>421</td>\n",
       "      <td>He is younger than his father</td>\n",
       "      <td>He is older than his father</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>423</td>\n",
       "      <td>People can go back to where they are after the...</td>\n",
       "      <td>People can't go back to where they are after t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>427</td>\n",
       "      <td>We will get pins and needles from sitting or s...</td>\n",
       "      <td>We will feel relaxed from sitting or standing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>430</td>\n",
       "      <td>Fireflies can make light</td>\n",
       "      <td>Fireflies are usually annoying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>432</td>\n",
       "      <td>Hail comes in the warm season</td>\n",
       "      <td>Hail comes in winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>436</td>\n",
       "      <td>Waste batteries can be thrown away at will</td>\n",
       "      <td>Waste batteries can't be thrown away at will</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1739</th>\n",
       "      <td>1740</td>\n",
       "      <td>where knowledge begins, science ends</td>\n",
       "      <td>where knowledge begins, religion ends</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1747</th>\n",
       "      <td>1748</td>\n",
       "      <td>football players wear short sleeves to protect...</td>\n",
       "      <td>football players wear short sleeves to lose heat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>1757</td>\n",
       "      <td>starving people care little about food sources</td>\n",
       "      <td>starving people care little about food quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1759</th>\n",
       "      <td>1760</td>\n",
       "      <td>boys usually cant wear dress in China</td>\n",
       "      <td>boys usually dont wear dress in China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>1775</td>\n",
       "      <td>one kilogram of stone is as heavy as one kilog...</td>\n",
       "      <td>one kilogram of stone is much heavier than a k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>1776</td>\n",
       "      <td>it's crazy to turn on the air conditioning on ...</td>\n",
       "      <td>it's crazy to turn on the electricity fans on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>1777</td>\n",
       "      <td>we need different passports to visit different...</td>\n",
       "      <td>we need different visas to visit different cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>1781</td>\n",
       "      <td>I always carry my desktop pc with me</td>\n",
       "      <td>I always carry my laptop with me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1788</th>\n",
       "      <td>1789</td>\n",
       "      <td>a open air park is a good place to stay on rai...</td>\n",
       "      <td>a library is a good place to stay on rainy days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>1790</td>\n",
       "      <td>most of the earth's surface is covered by water</td>\n",
       "      <td>most of the earth's surface is covered by dirt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>1795</td>\n",
       "      <td>I pressed the accelerator in my bicycle to spe...</td>\n",
       "      <td>I pressed the accelerator in my car to speed up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1801</th>\n",
       "      <td>1802</td>\n",
       "      <td>you can buy drinks from vending machines witho...</td>\n",
       "      <td>you can buy drinks from vending machines witho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1810</th>\n",
       "      <td>1811</td>\n",
       "      <td>girls wear skirts in winter for beauty</td>\n",
       "      <td>girls wear skirts in winter for warmth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1812</th>\n",
       "      <td>1813</td>\n",
       "      <td>he scored a crucial goal by hand in a soccer m...</td>\n",
       "      <td>he scored a crucial goal by head in a soccer m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>1824</td>\n",
       "      <td>you can definitely cook food well by following...</td>\n",
       "      <td>you may cook food well by following a recipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1849</th>\n",
       "      <td>1850</td>\n",
       "      <td>museum exhibits artifacts for everyone to learn</td>\n",
       "      <td>museum exhibits artifacts for sale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1856</th>\n",
       "      <td>1857</td>\n",
       "      <td>the young man offered his seat to the old lady...</td>\n",
       "      <td>the driver offered his seat to the old lady on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1869</th>\n",
       "      <td>1870</td>\n",
       "      <td>animals are pets</td>\n",
       "      <td>pets are animals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1873</th>\n",
       "      <td>1874</td>\n",
       "      <td>he was fined for smoking in his home</td>\n",
       "      <td>he was fined for smoking in the airplane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884</th>\n",
       "      <td>1885</td>\n",
       "      <td>Rats can't bite metal furniture</td>\n",
       "      <td>Rats can't bite wood furniture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1893</th>\n",
       "      <td>1894</td>\n",
       "      <td>I can take part in the soccer game in formal c...</td>\n",
       "      <td>I can take part in the soccer game in athletic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>1905</td>\n",
       "      <td>A rat can survive a fall from a five-floor bui...</td>\n",
       "      <td>A person can survive a fall from a five-floor ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1906</th>\n",
       "      <td>1907</td>\n",
       "      <td>He caught a cold and had a hot shower</td>\n",
       "      <td>He caught a cold and had a cold shower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>1918</td>\n",
       "      <td>Dry towels need to hang up to dry</td>\n",
       "      <td>Wet towels need to hang up to dry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>1938</td>\n",
       "      <td>julia pressed down on a piano key to play a music</td>\n",
       "      <td>julia pressed down on a piano key to make a sound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943</th>\n",
       "      <td>1944</td>\n",
       "      <td>the celebrity wore sunglasses to avoid recogni...</td>\n",
       "      <td>the celebrity wore sunglasses to help recognition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949</th>\n",
       "      <td>1950</td>\n",
       "      <td>her eyeglasses fogged up as she entered the sauna</td>\n",
       "      <td>her eyeglasses fogged up as she exited the sauna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1955</th>\n",
       "      <td>1956</td>\n",
       "      <td>she made an error in her calculations because ...</td>\n",
       "      <td>she made an error in her calculations because ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958</th>\n",
       "      <td>1959</td>\n",
       "      <td>the egg splattered after I dropped it</td>\n",
       "      <td>the egg splattered after I boiled it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>1967</td>\n",
       "      <td>the aggressive football coach lost his voice a...</td>\n",
       "      <td>the aggressive football coach lost his voice b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              sent0  \\\n",
       "82      83                      he opens the door with a lock   \n",
       "143    144             the Taj Mahal is made of white marbles   \n",
       "149    150               Mongolia is mass surrounded by water   \n",
       "186    187  Harry jumps high to throw the basketball into ...   \n",
       "190    191        Maria coughs when she breathes in fresh air   \n",
       "216    217  Carter opened the window of the airplane to ge...   \n",
       "248    249              She sharpened the pencil with a knife   \n",
       "258    259        I should take off my trousers when swimming   \n",
       "269    270                  a tiger is probable to beat a dog   \n",
       "287    288          if we are going to be late we should walk   \n",
       "303    304                           People are able to cheat   \n",
       "327    328                I will feel energetic after running   \n",
       "331    332             people usually eat ice cream in summer   \n",
       "332    333                    we wear thick clothes in winter   \n",
       "333    334  we can see white clouds and dark clouds in the...   \n",
       "344    345                          I can drink after driving   \n",
       "356    357                We communicate in the same language   \n",
       "370    371                    today I will go to my hometowns   \n",
       "371    372          My blood type is the same as some people.   \n",
       "385    386              Pushing a bike requires much strength   \n",
       "390    391                     blind people can watch nothing   \n",
       "391    392                    A child will be a child forever   \n",
       "397    398  Something that might happen when you diminish ...   \n",
       "418    419                No living thing can live in the sea   \n",
       "420    421                      He is younger than his father   \n",
       "422    423  People can go back to where they are after the...   \n",
       "426    427  We will get pins and needles from sitting or s...   \n",
       "429    430                           Fireflies can make light   \n",
       "431    432                      Hail comes in the warm season   \n",
       "435    436         Waste batteries can be thrown away at will   \n",
       "...    ...                                                ...   \n",
       "1739  1740               where knowledge begins, science ends   \n",
       "1747  1748  football players wear short sleeves to protect...   \n",
       "1756  1757     starving people care little about food sources   \n",
       "1759  1760             boys usually cant wear dress in China   \n",
       "1774  1775  one kilogram of stone is as heavy as one kilog...   \n",
       "1775  1776  it's crazy to turn on the air conditioning on ...   \n",
       "1776  1777  we need different passports to visit different...   \n",
       "1780  1781               I always carry my desktop pc with me   \n",
       "1788  1789  a open air park is a good place to stay on rai...   \n",
       "1789  1790    most of the earth's surface is covered by water   \n",
       "1794  1795  I pressed the accelerator in my bicycle to spe...   \n",
       "1801  1802  you can buy drinks from vending machines witho...   \n",
       "1810  1811             girls wear skirts in winter for beauty   \n",
       "1812  1813  he scored a crucial goal by hand in a soccer m...   \n",
       "1823  1824  you can definitely cook food well by following...   \n",
       "1849  1850    museum exhibits artifacts for everyone to learn   \n",
       "1856  1857  the young man offered his seat to the old lady...   \n",
       "1869  1870                                   animals are pets   \n",
       "1873  1874               he was fined for smoking in his home   \n",
       "1884  1885                    Rats can't bite metal furniture   \n",
       "1893  1894  I can take part in the soccer game in formal c...   \n",
       "1904  1905  A rat can survive a fall from a five-floor bui...   \n",
       "1906  1907              He caught a cold and had a hot shower   \n",
       "1917  1918                  Dry towels need to hang up to dry   \n",
       "1937  1938  julia pressed down on a piano key to play a music   \n",
       "1943  1944  the celebrity wore sunglasses to avoid recogni...   \n",
       "1949  1950  her eyeglasses fogged up as she entered the sauna   \n",
       "1955  1956  she made an error in her calculations because ...   \n",
       "1958  1959              the egg splattered after I dropped it   \n",
       "1966  1967  the aggressive football coach lost his voice a...   \n",
       "\n",
       "                                                  sent1  \n",
       "82                         he opens the door with a key  \n",
       "143               the Taj Mahal is made of white maples  \n",
       "149                  the UK is mass surrounded by water  \n",
       "186   Harry stoops down to throw the basketball into...  \n",
       "190              Maria coughs when she breathes in haze  \n",
       "216   Carter opened the ventilator of the airplane t...  \n",
       "248             She sharpened the pencil with an eraser  \n",
       "258       I should take off my underpants when swimming  \n",
       "269                   a dog is probable to beat a tiger  \n",
       "287            if we are going to be late we should run  \n",
       "303                   people are only able to be honest  \n",
       "327                    I will feel hungry after running  \n",
       "331              people usually eat ice cream in winter  \n",
       "332                      we wear thin clothes in winter  \n",
       "333             we can only see white clouds in the air  \n",
       "344                          I can drive after drinking  \n",
       "356               We communicate in different languages  \n",
       "370                      today I will go to my hometown  \n",
       "371              My blood type is the same as everyone.  \n",
       "385                Pushing a car requires much strength  \n",
       "390                       Blind people can watch the TV  \n",
       "391                         A child can become an adult  \n",
       "397   Something that might happen when you diminish ...  \n",
       "418              some living things can live in the sea  \n",
       "420                         He is older than his father  \n",
       "422   People can't go back to where they are after t...  \n",
       "426   We will feel relaxed from sitting or standing ...  \n",
       "429                      Fireflies are usually annoying  \n",
       "431                                Hail comes in winter  \n",
       "435        Waste batteries can't be thrown away at will  \n",
       "...                                                 ...  \n",
       "1739              where knowledge begins, religion ends  \n",
       "1747   football players wear short sleeves to lose heat  \n",
       "1756     starving people care little about food quality  \n",
       "1759             boys usually dont wear dress in China  \n",
       "1774  one kilogram of stone is much heavier than a k...  \n",
       "1775  it's crazy to turn on the electricity fans on ...  \n",
       "1776  we need different visas to visit different cou...  \n",
       "1780                   I always carry my laptop with me  \n",
       "1788    a library is a good place to stay on rainy days  \n",
       "1789     most of the earth's surface is covered by dirt  \n",
       "1794    I pressed the accelerator in my car to speed up  \n",
       "1801  you can buy drinks from vending machines witho...  \n",
       "1810             girls wear skirts in winter for warmth  \n",
       "1812  he scored a crucial goal by head in a soccer m...  \n",
       "1823       you may cook food well by following a recipe  \n",
       "1849                 museum exhibits artifacts for sale  \n",
       "1856  the driver offered his seat to the old lady on...  \n",
       "1869                                   pets are animals  \n",
       "1873           he was fined for smoking in the airplane  \n",
       "1884                     Rats can't bite wood furniture  \n",
       "1893  I can take part in the soccer game in athletic...  \n",
       "1904  A person can survive a fall from a five-floor ...  \n",
       "1906             He caught a cold and had a cold shower  \n",
       "1917                  Wet towels need to hang up to dry  \n",
       "1937  julia pressed down on a piano key to make a sound  \n",
       "1943  the celebrity wore sunglasses to help recognition  \n",
       "1949   her eyeglasses fogged up as she exited the sauna  \n",
       "1955  she made an error in her calculations because ...  \n",
       "1958               the egg splattered after I boiled it  \n",
       "1966  the aggressive football coach lost his voice b...  \n",
       "\n",
       "[165 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "CommonSense.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00492598dbd542c8a84592a5ac065991": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5b56c4372bcb459ea8418eeabc92d7fc",
       "IPY_MODEL_58ecfe855eef4271912a91187990e6fb"
      ],
      "layout": "IPY_MODEL_35cdabdbef024a6b81331ea10c614365"
     }
    },
    "03d93305b3754704ac24e5d960c6c5e2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "049d01a118444e5aaf684d467c0d07a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0c13faf3c61d4e739b43d3b2e2b0e4a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a7f9ba7b72ca4e9fbfd1995f9f046cf7",
       "IPY_MODEL_a564e74ce99b414bb2b3a288370abae0"
      ],
      "layout": "IPY_MODEL_1e07d8379d064f7c8fef772afe0a7ac2"
     }
    },
    "197df6e7f7724935994042f0dec842a4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e07d8379d064f7c8fef772afe0a7ac2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "26c778e84160499eaff2f073b05eec3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "2cde83d55edf427fa2fbf3e535beac09": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4903ddedfef04516b44f534517d07851",
       "IPY_MODEL_46f014b39fad4d0f9dfdaec07c10df3e"
      ],
      "layout": "IPY_MODEL_197df6e7f7724935994042f0dec842a4"
     }
    },
    "35cdabdbef024a6b81331ea10c614365": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "46f014b39fad4d0f9dfdaec07c10df3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_03d93305b3754704ac24e5d960c6c5e2",
      "placeholder": "",
      "style": "IPY_MODEL_f1ac8a5b3f7e420b97d76fbd536b435b",
      "value": "100% 232k/232k [00:00&lt;00:00, 3.94MB/s]"
     }
    },
    "4903ddedfef04516b44f534517d07851": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading",
      "description_tooltip": null,
      "layout": "IPY_MODEL_584bead4df0943cbbd1663243d2bd679",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ef49a5d738ba4cbe8c5996a099f460ed",
      "value": 231508
     }
    },
    "4c5f563401e840da9afd13fea555d516": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "584bead4df0943cbbd1663243d2bd679": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58ecfe855eef4271912a91187990e6fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_663b3f4172b94ca98738f24923b0fc02",
      "placeholder": "",
      "style": "IPY_MODEL_f85cef55a5724c5ab574f1c09f770d82",
      "value": "100% 440M/440M [00:37&lt;00:00, 11.8MB/s]"
     }
    },
    "5b56c4372bcb459ea8418eeabc92d7fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading",
      "description_tooltip": null,
      "layout": "IPY_MODEL_931405db76534b1db2a3a82103385cbf",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_26c778e84160499eaff2f073b05eec3b",
      "value": 440473133
     }
    },
    "663b3f4172b94ca98738f24923b0fc02": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "67b267518b1a46b4ad81f50797c1c6e1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "931405db76534b1db2a3a82103385cbf": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a564e74ce99b414bb2b3a288370abae0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4c5f563401e840da9afd13fea555d516",
      "placeholder": "",
      "style": "IPY_MODEL_049d01a118444e5aaf684d467c0d07a6",
      "value": "100% 361/361 [00:00&lt;00:00, 10.6kB/s]"
     }
    },
    "a7f9ba7b72ca4e9fbfd1995f9f046cf7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading",
      "description_tooltip": null,
      "layout": "IPY_MODEL_67b267518b1a46b4ad81f50797c1c6e1",
      "max": 361,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b263c5db98604c4195acaddc8815fa88",
      "value": 361
     }
    },
    "b263c5db98604c4195acaddc8815fa88": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ef49a5d738ba4cbe8c5996a099f460ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f1ac8a5b3f7e420b97d76fbd536b435b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f85cef55a5724c5ab574f1c09f770d82": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
